{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Importing the required packages \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy as np\n",
    "import time \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Function for web scraping \n",
    "\n",
    "\n",
    "\n",
    "def scraper_2(driver):\n",
    "\n",
    "    gifts = driver.find_elements(By.CSS_SELECTOR, 'figure[data-test=\"product\"]')\n",
    "\n",
    "    #print(gifts) \n",
    "    #print(len(gifts))\n",
    "    \n",
    "    gift_ideas = []\n",
    "    gift_prices = []\n",
    "    gift_links = []\n",
    "    gift_images = []\n",
    "\n",
    "    for gift in gifts:\n",
    "            #Iterate over every item of information\n",
    "        gift_name = gift.find_element(By.CSS_SELECTOR, \"h2[aria-label]\").text\n",
    "        \n",
    "        if gift_name not in total_ideas:\n",
    "            gift_ideas.append(gift_name)\n",
    "            print(gift_name)\n",
    "                #Selects all the gift names \n",
    "                #Converts the HTML into text and saves it \n",
    "\n",
    "            try:\n",
    "                gift_prices_pound = gift.find_element(By.CLASS_NAME, \"a-price-whole\").text\n",
    "                gift_prices_pence = gift.find_element(By.CLASS_NAME, \"a-price-fraction\").text\n",
    "\n",
    "                price = gift_prices_pound + \".\" + gift_prices_pence\n",
    "                gift_prices.append(price)\n",
    "                print(price)\n",
    "                    #Finds the price normally\n",
    "\n",
    "            except:\n",
    "                price = gift.find_element(By.CLASS_NAME, \"a-color-base\")\n",
    "                gift_prices.append(price)\n",
    "                print(price)\n",
    "                    #This finds the price if not in the normal location \n",
    "\n",
    "            gift_link = gift.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            gift_links.append(gift_link)\n",
    "            print(gift_link)\n",
    "                #Seletcs the link for the products \n",
    "                \n",
    "            gift_image = gift.find_element(By.CLASS_NAME, \"s-image\").get_attribute(\"src\")\n",
    "            gift_images.append(gift_image)\n",
    "            print(gift_image)\n",
    "\n",
    "            print()\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return gift_ideas, gift_prices, gift_links, gift_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Applying this Function\n",
    "\n",
    "total_ideas = []\n",
    "total_prices = []\n",
    "total_links = []\n",
    "total_images = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#url = \"https://www.amazon.co.uk/gcx/Gifts-for-everyone/gfhz/?scrollState=eyJpdGVtSW5kZXgiOjAsInNjcm9sbE9mZnNldCI6Njg4LjM2MjQ4Nzc5Mjk2ODh9&sectionManagerState=eyJzZWN0aW9uVHlwZUVuZEluZGV4Ijp7ImFtYWJvdCI6MH19\"\n",
    "#url = \"https://www.amazon.co.uk/gcx/Gifts-for-Men/gfhz/category?categoryId=adult-male&scrollState=eyJpdGVtSW5kZXgiOjAsInNjcm9sbE9mZnNldCI6MzkwLjgwMDAxODMxMDU0Njl9&sectionManagerState=eyJzZWN0aW9uVHlwZUVuZEluZGV4Ijp7ImFtYWJvdCI6MH19\"\n",
    "#url = \"https://www.amazon.co.uk/gcx/Gifts-for-Women/gfhz/category?categoryId=adult-female&scrollState=eyJpdGVtSW5kZXgiOjAsInNjcm9sbE9mZnNldCI6MzkwLjgwMDAxODMxMDU0Njl9&sectionManagerState=eyJzZWN0aW9uVHlwZUVuZEluZGV4Ijp7ImFtYWJvdCI6MH19\"\n",
    "    #Each of these links is where I got the Amazon Data from \n",
    "    #Repeat below for each of the links \n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        #Scrolls the webpage to the bottom\n",
    "    time.sleep(2)\n",
    "    \n",
    "    ideas, prices, links, images = scraper_2(driver)\n",
    "    \n",
    "    total_ideas.extend(ideas)\n",
    "    total_links.extend(links)\n",
    "    total_prices.extend(prices)\n",
    "    total_images.extend(images)\n",
    "    \n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    if new_height == last_height:\n",
    "        print(\"Page Scraping Complete\")\n",
    "        print()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        #ideas, prices, links = scraper_test(driver)\n",
    "            #Need to remove to prevent overlap\n",
    "        \n",
    "        break\n",
    "        \n",
    "    last_height = new_height\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "\n",
    "#Saving the data \n",
    "\n",
    "gift_data = {\n",
    "    \"Name\" : total_ideas,\n",
    "    \"Price\" : total_prices,\n",
    "    \"Link\" : total_links,\n",
    "    \"Image URL\" : total_images}\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "    #This prevents the automatic truncation in pandas dataframes \n",
    "\n",
    "gift_dataframe = pd.DataFrame(gift_data)\n",
    "\n",
    "gift_dataframe.to_csv(\"Gift_Data.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
